{"cells":[{"cell_type":"markdown","metadata":{"id":"fego90Rbzy7z"},"source":["# **ResNet-50 강의 노트**\n","\n","본 노트북에서는 ResNet-50 모델에 대해 간략히 살펴보고, PyTorch를 이용해 직접 구현해보겠습니다.\n","\n","## 목차\n","1. ResNet(Residual Network) 개요\n","2. ResNet-50 구조\n","3. Residual Block (Bottleneck) 개념도\n","4. PyTorch 기반 코드 구현 예시\n","5. 학습 방법 개요\n","6. 요약 및 강의 포인트\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"4GOY6YL_zy70"},"source":["## 1. ResNet(Residual Network) 개요\n","\n","**등장 배경**\n","- 딥러닝 모델이 깊어질수록 일반적으로 성능이 향상되는 경향이 있지만, 지나치게 깊은 네트워크는 기울기 소실(vanishing gradient) 등 학습 난이도가 크게 증가합니다.\n","- ResNet은 이러한 문제를 해결하기 위해 **잔차 학습(Residual Learning)** 이라는 개념을 도입하였습니다.\n","\n","**스킵 연결(Skip Connection)과 Residual Block**\n","- Residual Block에서는 입력 \\( x \\)와 출력 \\( F(x) \\)을 직접 연결(스킵 연결)해 \\( y = F(x) + x \\) 형태로 만듭니다.\n","- 이 구조를 통해 깊은 네트워크에서 발생하는 기울기 소실을 완화하고, 학습 안정성을 높입니다.\n"]},{"cell_type":"markdown","metadata":{"id":"m9VCic9tzy70"},"source":["## 2. ResNet-50 구조\n","\n","ResNet-50은 이름에서 알 수 있듯, **50층**으로 구성된 깊은 CNN 모델입니다.\n","\n","### 2.1 구성 요약\n","1. **초기 단계(Stem)**\n","   - 7×7 Conv(stride=2, 채널=64)\n","   - Max Pooling(3×3, stride=2)\n","2. **Conv2_x 블록**\n","   - 3개의 Bottleneck Block\n","3. **Conv3_x 블록**\n","   - 4개의 Bottleneck Block\n","4. **Conv4_x 블록**\n","   - 6개의 Bottleneck Block\n","5. **Conv5_x 블록**\n","   - 3개의 Bottleneck Block\n","6. **분류 헤드(Classifier)**\n","   - Global Average Pooling + FC(1000 클래스)\n","\n","### 2.2 전체 개념도\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*tH9evuOFqk8F41FG.png\" alt=\"ResNet-50 구조\" width=\"600\" />\n","\n","위 그림은 ResNet-50(또는 34, 101 등의 변형)에 대한 개념적 구조를 보여줍니다. 실제로는 Bottleneck 모듈의 반복 횟수에 따라 깊이가 달라집니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a4TNCcT0zy71"},"source":["## 3. Residual Block (Bottleneck) 개념도\n","\n","아래는 Bottleneck 블록의 구조를 단순화한 개념 그림입니다.\n","\n","<img src=\"https://i.sstatic.net/kbiIG.png\" alt=\"Bottleneck block\" width=\"500\" />\n","\n","\n","이러한 잔차 학습 구조(\\( y = F(x) + x \\))를 통해 네트워크가 보다 쉽게 학습할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"pBIB4rp1zy71"},"source":["## 4. PyTorch 기반 코드 구현 예시\n","\n","### 4.1 TorchVision 활용 (간단 예시)\n","가장 쉽게 ResNet-50을 사용하려면 `torchvision.models`에서 미리 정의된 모델을 가져오면 됩니다.\n"]},{"cell_type":"code","metadata":{"execution_count":null,"id":"fGjm0GzDzy71"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","# 미리 학습되지 않은(랜덤 초기화) ResNet-50\n","resnet50 = models.resnet50(pretrained=False)\n","\n","# 미리 학습된(pretrained) ResNet-50\n","resnet50_pretrained = models.resnet50(pretrained=True)\n","\n","# 마지막 FC 레이어 수정 (예: 클래스 수 10개로 변경)\n","# Imagenet으로 학습된 모델이라 마지막 레이어를 수정, 원하는 목적으로 분류하기 위해\n","num_features = resnet50.fc.in_features\n","resnet50.fc = nn.Linear(num_features, 10)\n","print(resnet50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6M90kKNCzy72"},"source":["### 4.2 Bottleneck 블록 직접 구현하기\n","학습용으로는 Bottleneck 블록을 직접 구현하여 구조를 이해해볼 수도 있습니다.\n"]},{"cell_type":"code","metadata":{"execution_count":null,"id":"HfyHiHf_zy72"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4  # Bottleneck 확장 배수\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","\n","        # 1x1 Conv\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        # 3x3 Conv\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # 1x1 Conv (채널 확장)\n","        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n","                               kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        # downsample이 있으면 skip connection의 차원을 맞춤\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"qjYa2jIxzy72"},"source":["### 4.3 ResNet-50 전체 구조 구현\n","아래는 ResNet-50 모델을 (단순화하여) 직접 구현한 예시입니다. 실제로는 더욱 세부적인 요소가 있지만, 주요 골자는 동일합니다.\n"]},{"cell_type":"code","metadata":{"execution_count":null,"id":"bGh09t1Dzy72"},"source":["class MyResNet50(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(MyResNet50, self).__init__()\n","\n","        # 초기 Stem\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # inplanes 설정\n","        self.inplanes = 64\n","\n","        # 레이어 구성\n","        self.layer1 = self._make_layer(Bottleneck, 64,  3, stride=1)\n","        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n","        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)\n","        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)\n","\n","        # 분류기\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n","\n","    def _make_layer(self, block, out_channels, blocks, stride=1):\n","        downsample = None\n","\n","        # stride!=1이거나, 채널 수가 맞지 않으면 다운샘플 구성\n","        if stride != 1 or self.inplanes != out_channels * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, out_channels * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels * block.expansion)\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, out_channels, stride, downsample))\n","        self.inplanes = out_channels * block.expansion\n","\n","        # 나머지 블록은 stride=1\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        # Stem\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        # 4개의 레이어\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        # 분류\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x\n","\n","# 모델 예시 생성\n","model = MyResNet50(num_classes=1000)\n","print(model)"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"2jqJIx1dzy73"},"source":["## 5. 학습 방법 개요\n","1. **데이터셋 준비**: ImageNet, CIFAR-10 등\n","2. **DataLoader 설정**: 배치 크기, 셔플, 증강(augmentation) 등\n","3. **optimizer 및 loss 함수 설정**: 예) `torch.optim.SGD`, `nn.CrossEntropyLoss`\n","4. **Training Loop**:\n","   - 입력 → 모델 → 손실 계산 → `loss.backward()` → `optimizer.step()`\n","5. **Validation / Test**: 일정 에폭마다 검증 세트, 테스트 세트 정확도 확인\n"]},{"cell_type":"markdown","metadata":{"id":"nxwh_Yvdzy73"},"source":["## 6. 요약 및 강의 포인트\n","- **Residual Learning**: 깊은 신경망의 기울기 소실을 완화하고 학습 효율을 개선\n","- **Bottleneck 구조**: 1×1 Conv → 3×3 Conv → 1×1 Conv 순으로 채널 압축 & 확장\n","- **ResNet-50**: 50층 깊이의 모델이며, Residual Block으로 구성\n","- **PyTorch 구현**: `torchvision.models.resnet50` 간편 사용, 또는 Bottleneck과 ResNet 클래스를 직접 구현\n","- **전이 학습**: 사전 학습된 가중치를 활용하면 적은 데이터로도 좋은 성능을 낼 수 있음\n","\n","---\n","**추가 자료**\n","- [논문: Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n","- [PyTorch 공식 튜토리얼](https://pytorch.org/tutorials/)\n","- [TorchVision 모델 문서](https://pytorch.org/vision/stable/models.html)\n","\n","이상으로 **ResNet-50**에 대한 핵심 개념과 코드를 살펴보았습니다. 필요한 경우, CIFAR-10 등 소규모 데이터셋으로 실습을 진행하면서 실제 학습 과정을 경험해 보실 수 있습니다."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7"}},"nbformat":4,"nbformat_minor":0}